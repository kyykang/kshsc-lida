#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIDA è‡ªå®šä¹‰LLMé…ç½®æ–‡ä»¶ - OpenAIå®¢æˆ·ç«¯æ–¹å¼
é…ç½®ç±»å‹: openai_compatible
ç”Ÿæˆæ—¶é—´: è‡ªåŠ¨ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
1. from custom_llm_config_working import get_lida_manager
2. lida = get_lida_manager()
3. å¼€å§‹ä½¿ç”¨LIDAè¿›è¡Œæ•°æ®å¯è§†åŒ–
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def get_lida_manager():
    """
    è·å–é…ç½®å¥½çš„LIDAç®¡ç†å™¨
    ä½¿ç”¨ç›´æ¥çš„OpenAIå®¢æˆ·ç«¯æ–¹å¼
    
    è¿”å›:
        Manager: é…ç½®å¥½çš„LIDAç®¡ç†å™¨å®ä¾‹
    """
    from lida import Manager
    import openai
    
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–è‡ªå®šä¹‰LLMæœåŠ¡...")
    
    # åˆ›å»ºè‡ªå®šä¹‰OpenAIå®¢æˆ·ç«¯
    client = openai.OpenAI(
        base_url="http://10.254.28.17:30000/v1",
        api_key="EMPTY"
    )
    
    # åˆ›å»ºä¸€ä¸ªå…¼å®¹LIDAçš„æ–‡æœ¬ç”Ÿæˆå™¨åŒ…è£…å™¨
    class CustomTextGenerator:
        def __init__(self, client):
            self.client = client
            # æ·»åŠ LIDAéœ€è¦çš„å±æ€§
            self.provider = "openai"  # è®¾ç½®providerå±æ€§
            self.model = "default"    # è®¾ç½®æ¨¡å‹åç§°
            
        def generate(self, messages=None, config=None, **kwargs):
            """
            ç”Ÿæˆæ–‡æœ¬çš„æ–¹æ³•ï¼Œå…¼å®¹LIDAçš„è°ƒç”¨æ–¹å¼
            
            å‚æ•°:
                messages: æ¶ˆæ¯åˆ—è¡¨ï¼ŒLIDAä¼ å…¥çš„å¯¹è¯æ ¼å¼
                config: TextGenerationConfigå¯¹è±¡ï¼ŒåŒ…å«ç”Ÿæˆé…ç½®
                **kwargs: å…¶ä»–å‚æ•°
            
            è¿”å›:
                TextGenerationResponseæ ¼å¼çš„å¯¹è±¡
            """
            # å¤„ç†ä¸åŒçš„è°ƒç”¨æ–¹å¼
            if messages is None and len(kwargs) > 0:
                # å…¼å®¹æ—§çš„promptæ–¹å¼è°ƒç”¨
                prompt = kwargs.get('prompt', '')
                messages = [{"role": "user", "content": prompt}]
            elif messages is None:
                raise ValueError("å¿…é¡»æä¾›messageså‚æ•°")
            
            # ä»configä¸­è·å–å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰configåˆ™ä½¿ç”¨é»˜è®¤å€¼
            temperature = 0.7
            max_tokens = 2048
            n = 1
            
            if config:
                temperature = getattr(config, 'temperature', 0.7)
                max_tokens = getattr(config, 'max_tokens', 2048)
                n = getattr(config, 'n', 1)
            
            try:
                response = self.client.chat.completions.create(
                    model="default",
                    messages=messages,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    n=n
                )
                
                # åˆ›å»ºå…¼å®¹LIDAçš„å“åº”æ ¼å¼
                class TextGenerationResponse:
                    def __init__(self, response):
                        self.text = []
                        for choice in response.choices:
                            self.text.append({
                                "content": choice.message.content
                            })
                
                return TextGenerationResponse(response)
                
            except Exception as e:
                print(f"âŒ LLMè°ƒç”¨å¤±è´¥: {e}")
                # è¿”å›ç©ºå“åº”ä»¥é¿å…å´©æºƒ
                class EmptyResponse:
                    def __init__(self):
                        self.text = [{"content": ""}]
                return EmptyResponse()
    
    text_gen = CustomTextGenerator(client)
    
    # åˆ›å»ºLIDAç®¡ç†å™¨
    lida_manager = Manager(text_gen=text_gen)
    
    print("âœ… è‡ªå®šä¹‰LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼")
    print(f"APIåœ°å€: http://10.254.28.17:30000/v1")
    print(f"æ¨¡å‹åç§°: default")
    
    return lida_manager

def test_llm_service():
    """
    æµ‹è¯•LLMæœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    try:
        lida = get_lida_manager()
        print("\nğŸ§ª æ­£åœ¨æµ‹è¯•LLMæœåŠ¡...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€å•çš„æµ‹è¯•é€»è¾‘
        print("âœ… LLMæœåŠ¡æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ LLMæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("LIDA è‡ªå®šä¹‰LLMé…ç½®")
    print("=" * 30)
    
    # æµ‹è¯•æœåŠ¡
    if test_llm_service():
        print("\nğŸ‰ é…ç½®æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨LIDAäº†")
        print("\nğŸ“ ä½¿ç”¨ç¤ºä¾‹:")
        print("from custom_llm_config_working import get_lida_manager")
        print("lida = get_lida_manager()")
        print("summary = lida.summarize('your_data.csv')")
    else:
        print("\nâš ï¸  é…ç½®å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥è®¾ç½®")
