#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIDA è‡ªå®šä¹‰LLMæœåŠ¡é…ç½®å·¥å…·
å¸®åŠ©ç”¨æˆ·å°†è‡ªå·±çš„LLMæœåŠ¡é›†æˆåˆ°LIDAé¡¹ç›®ä¸­

æ”¯æŒçš„æœåŠ¡ç±»å‹:
1. OpenAIå…¼å®¹API (æ¨è)
2. è‡ªå®šä¹‰HTTP API
3. æœ¬åœ°æ¨¡å‹æœåŠ¡

ä½œè€…: AIåŠ©æ‰‹
æ—¥æœŸ: 2024
"""

import os
import sys
import json
import requests
from datetime import datetime
from pathlib import Path

def test_api_connection(api_base, api_key, model_name, test_prompt="Hello, how are you?"):
    """
    æµ‹è¯•APIè¿æ¥æ˜¯å¦æ­£å¸¸
    
    å‚æ•°:
        api_base (str): APIåŸºç¡€URL
        api_key (str): APIå¯†é’¥
        model_name (str): æ¨¡å‹åç§°
        test_prompt (str): æµ‹è¯•æç¤ºè¯
    
    è¿”å›:
        bool: è¿æ¥æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    print(f"ğŸ” æ­£åœ¨æµ‹è¯•APIè¿æ¥...")
    
    try:
        # æ„å»ºè¯·æ±‚URL
        if api_base.endswith('/v1'):
            url = f"{api_base}/chat/completions"
        elif api_base.endswith('/v1/'):
            url = f"{api_base}chat/completions"
        else:
            url = f"{api_base}/v1/chat/completions"
        
        # æ„å»ºè¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            "model": model_name,
            "messages": [
                {"role": "user", "content": test_prompt}
            ],
            "max_tokens": 50,
            "temperature": 0.7
        }
        
        print(f"è¯·æ±‚URL: {url}")
        print(f"æ¨¡å‹åç§°: {model_name}")
        
        # å‘é€æµ‹è¯•è¯·æ±‚
        response = requests.post(url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                reply = result['choices'][0]['message']['content']
                print(f"âœ… APIè¿æ¥æˆåŠŸï¼")
                print(f"æµ‹è¯•å›å¤: {reply[:100]}...")
                return True
            else:
                print(f"âŒ APIå“åº”æ ¼å¼å¼‚å¸¸: {result}")
                return False
        else:
            print(f"âŒ APIè¯·æ±‚å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return False
            
    except requests.exceptions.Timeout:
        print("âŒ è¯·æ±‚è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æœåŠ¡å™¨çŠ¶æ€")
        return False
    except requests.exceptions.ConnectionError:
        print("âŒ è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIåœ°å€æ˜¯å¦æ­£ç¡®")
        return False
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def setup_openai_compatible_api():
    """
    é…ç½®OpenAIå…¼å®¹çš„APIæœåŠ¡
    è¿™æ˜¯æœ€å¸¸è§çš„é…ç½®æ–¹å¼ï¼Œæ”¯æŒå¤§å¤šæ•°LLMæœåŠ¡æä¾›å•†
    """
    print("ğŸ”§ é…ç½®OpenAIå…¼å®¹APIæœåŠ¡")
    print("=" * 50)
    
    print("\nğŸ“ è¯·è¾“å…¥æ‚¨çš„LLMæœåŠ¡ä¿¡æ¯:")
    
    # è·å–ç”¨æˆ·è¾“å…¥
    api_base = input("APIåŸºç¡€URL (ä¾‹: http://10.254.28.17:30000): ").strip()
    if not api_base:
        print("âŒ APIåŸºç¡€URLä¸èƒ½ä¸ºç©º")
        return None
    
    # ç¡®ä¿URLæ ¼å¼æ­£ç¡®
    if not api_base.startswith('http'):
        api_base = f"http://{api_base}"
    
    api_key = input("APIå¯†é’¥ (å¦‚æœä¸éœ€è¦å¯ç›´æ¥å›è½¦): ").strip()
    if not api_key:
        api_key = "EMPTY"  # å¾ˆå¤šæœ¬åœ°æœåŠ¡ä¸éœ€è¦çœŸå®å¯†é’¥
    
    model_name = input("æ¨¡å‹åç§° (ä¾‹: gpt-3.5-turbo, llama2ç­‰): ").strip()
    if not model_name:
        print("âŒ æ¨¡å‹åç§°ä¸èƒ½ä¸ºç©º")
        return None
    
    max_tokens = input("æœ€å¤§tokenæ•° [2048]: ").strip()
    max_tokens = int(max_tokens) if max_tokens.isdigit() else 2048
    
    print("\nğŸ“‹ é…ç½®ä¿¡æ¯ç¡®è®¤:")
    print(f"APIåœ°å€: {api_base}")
    print(f"APIå¯†é’¥: {'***' if api_key != 'EMPTY' else 'EMPTY'}")
    print(f"æ¨¡å‹åç§°: {model_name}")
    print(f"æœ€å¤§tokens: {max_tokens}")
    
    confirm = input("\nç¡®è®¤é…ç½®? (y/n): ").strip().lower()
    if confirm != 'y':
        print("âŒ ç”¨æˆ·å–æ¶ˆé…ç½®")
        return None
    
    # æµ‹è¯•APIè¿æ¥
    if not test_api_connection(api_base, api_key, model_name):
        retry = input("\nâš ï¸  APIæµ‹è¯•å¤±è´¥ï¼Œæ˜¯å¦ç»§ç»­ä¿å­˜é…ç½®? (y/n): ").strip().lower()
        if retry != 'y':
            return None
    
    # è¿”å›é…ç½®ä¿¡æ¯
    config = {
        'type': 'openai_compatible',
        'api_base': api_base,
        'api_key': api_key,
        'model_name': model_name,
        'max_tokens': max_tokens
    }
    
    return config

def setup_custom_http_api():
    """
    é…ç½®è‡ªå®šä¹‰HTTP APIæœåŠ¡
    é€‚ç”¨äºéOpenAIå…¼å®¹çš„è‡ªå®šä¹‰API
    """
    print("ğŸ”§ é…ç½®è‡ªå®šä¹‰HTTP APIæœåŠ¡")
    print("=" * 50)
    print("\nâš ï¸  æ³¨æ„: æ­¤é€‰é¡¹éœ€è¦æ‚¨è‡ªå·±å®ç°APIé€‚é…å™¨")
    print("å»ºè®®ä¼˜å…ˆå°è¯•OpenAIå…¼å®¹APIé…ç½®")
    
    api_url = input("\nAPIå®Œæ•´URL: ").strip()
    if not api_url:
        print("âŒ API URLä¸èƒ½ä¸ºç©º")
        return None
    
    headers = {}
    print("\nè¯·è¾“å…¥HTTPè¯·æ±‚å¤´ (å¯é€‰ï¼Œç›´æ¥å›è½¦è·³è¿‡):")
    while True:
        key = input("è¯·æ±‚å¤´åç§° (ç›´æ¥å›è½¦ç»“æŸ): ").strip()
        if not key:
            break
        value = input(f"{key}çš„å€¼: ").strip()
        if value:
            headers[key] = value
    
    config = {
        'type': 'custom_http',
        'api_url': api_url,
        'headers': headers
    }
    
    return config

def generate_config_file(config):
    """
    ç”ŸæˆLIDAé…ç½®æ–‡ä»¶
    
    å‚æ•°:
        config (dict): é…ç½®ä¿¡æ¯
    
    è¿”å›:
        str: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    config_file = "custom_llm_config.py"
    
    # ç”Ÿæˆé…ç½®æ–‡ä»¶å†…å®¹
    config_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIDA è‡ªå®šä¹‰LLMé…ç½®æ–‡ä»¶
é…ç½®ç±»å‹: {config['type']}
ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

ä½¿ç”¨æ–¹æ³•:
1. from custom_llm_config import get_lida_manager
2. lida = get_lida_manager()
3. å¼€å§‹ä½¿ç”¨LIDAè¿›è¡Œæ•°æ®å¯è§†åŒ–
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def get_lida_manager():
    """
    è·å–é…ç½®å¥½çš„LIDAç®¡ç†å™¨
    
    è¿”å›:
        Manager: é…ç½®å¥½çš„LIDAç®¡ç†å™¨å®ä¾‹
    """
    from lida import Manager, llm
    
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–è‡ªå®šä¹‰LLMæœåŠ¡...")
    
'''
    
    if config['type'] == 'openai_compatible':
        config_content += f'''
    # OpenAIå…¼å®¹APIé…ç½®
    model_details = [{{
        'name': "{config['model_name']}",
        'max_tokens': {config['max_tokens']},
        'model': {{
            'provider': 'openai',
            'parameters': {{'model': "{config['model_name']}"}}
        }}
    }}]
    
    # åˆ›å»ºæ–‡æœ¬ç”Ÿæˆå™¨
    text_gen = llm(
        provider="openai",
        api_base="{config['api_base']}",
        api_key="{config['api_key']}",
        models=model_details
    )
    
    # åˆ›å»ºLIDAç®¡ç†å™¨
    lida_manager = Manager(text_gen=text_gen)
    
    print("âœ… è‡ªå®šä¹‰LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼")
    print(f"APIåœ°å€: {config['api_base']}")
    print(f"æ¨¡å‹åç§°: {config['model_name']}")
    
    return lida_manager
'''
    
    elif config['type'] == 'custom_http':
        config_content += f'''
    # è‡ªå®šä¹‰HTTP APIé…ç½®
    # æ³¨æ„: éœ€è¦æ‚¨è‡ªå·±å®ç°APIé€‚é…é€»è¾‘
    
    import requests
    
    class CustomLLMProvider:
        def __init__(self):
            self.api_url = "{config['api_url']}"
            self.headers = {config['headers']}
        
        def generate(self, prompt, **kwargs):
            # åœ¨è¿™é‡Œå®ç°æ‚¨çš„APIè°ƒç”¨é€»è¾‘
            # è¿”å›ç”Ÿæˆçš„æ–‡æœ¬
            pass
    
    # è¿™é‡Œéœ€è¦æ‚¨æ ¹æ®å®é™…APIå®ç°é€‚é…å™¨
    # å»ºè®®ä½¿ç”¨OpenAIå…¼å®¹APIé…ç½®
    raise NotImplementedError("è‡ªå®šä¹‰HTTP APIéœ€è¦æ‰‹åŠ¨å®ç°é€‚é…å™¨")
'''
    
    config_content += '''

def test_llm_service():
    """
    æµ‹è¯•LLMæœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    try:
        lida = get_lida_manager()
        print("\nğŸ§ª æ­£åœ¨æµ‹è¯•LLMæœåŠ¡...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€å•çš„æµ‹è¯•é€»è¾‘
        print("âœ… LLMæœåŠ¡æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ LLMæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("LIDA è‡ªå®šä¹‰LLMé…ç½®")
    print("=" * 30)
    
    # æµ‹è¯•æœåŠ¡
    if test_llm_service():
        print("\nğŸ‰ é…ç½®æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨LIDAäº†")
        print("\nğŸ“ ä½¿ç”¨ç¤ºä¾‹:")
        print("from custom_llm_config import get_lida_manager")
        print("lida = get_lida_manager()")
        print("summary = lida.summarize('your_data.csv')")
    else:
        print("\nâš ï¸  é…ç½®å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥è®¾ç½®")
'''
    
    # å†™å…¥é…ç½®æ–‡ä»¶
    with open(config_file, 'w', encoding='utf-8') as f:
        f.write(config_content)
    
    print(f"\nğŸ’¾ é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_file}")
    return config_file

def generate_startup_script(config):
    """
    ç”Ÿæˆå¯åŠ¨è„šæœ¬
    
    å‚æ•°:
        config (dict): é…ç½®ä¿¡æ¯
    
    è¿”å›:
        str: å¯åŠ¨è„šæœ¬è·¯å¾„
    """
    script_file = "start_lida_with_custom_llm.py"
    
    script_content = f'''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIDA è‡ªå®šä¹‰LLMå¯åŠ¨è„šæœ¬
ä½¿ç”¨æ‚¨é…ç½®çš„è‡ªå®šä¹‰LLMæœåŠ¡å¯åŠ¨LIDA Webç•Œé¢

ä½¿ç”¨æ–¹æ³•:
python start_lida_with_custom_llm.py
"""

import os
import sys
import uvicorn
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def main():
    """
    å¯åŠ¨LIDA WebæœåŠ¡
    """
    print("ğŸš€ å¯åŠ¨LIDAè‡ªå®šä¹‰LLM WebæœåŠ¡")
    print("=" * 40)
    
    try:
        # å¯¼å…¥è‡ªå®šä¹‰é…ç½®
        from custom_llm_config import get_lida_manager
        
        # åˆå§‹åŒ–LIDAç®¡ç†å™¨
        lida_manager = get_lida_manager()
        
        # åˆ›å»ºWebåº”ç”¨
        from lida.web.app import create_app
        app = create_app(lida_manager)
        
        print("\nğŸŒ å¯åŠ¨WebæœåŠ¡å™¨...")
        print("è®¿é—®åœ°å€: http://localhost:8080")
        print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
        
        # å¯åŠ¨æœåŠ¡å™¨
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8080,
            log_level="info"
        )
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {{e}}")
        print("è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½®custom_llm_config.py")
    except Exception as e:
        print(f"âŒ å¯åŠ¨å¤±è´¥: {{e}}")
        sys.exit(1)

if __name__ == "__main__":
    main()
'''
    
    # å†™å…¥å¯åŠ¨è„šæœ¬
    with open(script_file, 'w', encoding='utf-8') as f:
        f.write(script_content)
    
    # è®¾ç½®æ‰§è¡Œæƒé™
    os.chmod(script_file, 0o755)
    
    print(f"ğŸ’¾ å¯åŠ¨è„šæœ¬å·²ç”Ÿæˆ: {script_file}")
    return script_file

def main():
    """
    ä¸»å‡½æ•°ï¼šé…ç½®å‘å¯¼
    """
    print("ğŸ¯ LIDA è‡ªå®šä¹‰LLMæœåŠ¡é…ç½®å·¥å…·")
    print("=" * 50)
    print("\næ­¤å·¥å…·å°†å¸®åŠ©æ‚¨å°†è‡ªå·±çš„LLMæœåŠ¡é›†æˆåˆ°LIDAé¡¹ç›®ä¸­")
    
    while True:
        print("\nğŸ“‹ è¯·é€‰æ‹©é…ç½®ç±»å‹:")
        print("1. OpenAIå…¼å®¹API (æ¨è)")
        print("2. è‡ªå®šä¹‰HTTP API (é«˜çº§)")
        print("3. é€€å‡º")
        
        try:
            choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
            
            if choice == "1":
                config = setup_openai_compatible_api()
                if config:
                    # ç”Ÿæˆé…ç½®æ–‡ä»¶
                    config_file = generate_config_file(config)
                    startup_script = generate_startup_script(config)
                    
                    print("\nğŸ‰ é…ç½®å®Œæˆï¼")
                    print("\nğŸ“ ä¸‹ä¸€æ­¥æ“ä½œ:")
                    print(f"1. æµ‹è¯•é…ç½®: python {config_file}")
                    print(f"2. å¯åŠ¨Webç•Œé¢: python {startup_script}")
                    print("3. æˆ–è€…åœ¨ä»£ç ä¸­ä½¿ç”¨:")
                    print("   from custom_llm_config import get_lida_manager")
                    print("   lida = get_lida_manager()")
                    
                    break
                    
            elif choice == "2":
                config = setup_custom_http_api()
                if config:
                    config_file = generate_config_file(config)
                    print("\nâš ï¸  è‡ªå®šä¹‰HTTP APIé…ç½®å·²ç”Ÿæˆ")
                    print(f"è¯·æ‰‹åŠ¨ç¼–è¾‘ {config_file} å®ç°APIé€‚é…é€»è¾‘")
                    break
                    
            elif choice == "3":
                print("ğŸ‘‹ é€€å‡ºé…ç½®å·¥å…·")
                sys.exit(0)
                
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-3")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·å–æ¶ˆæ“ä½œ")
            sys.exit(0)
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
    
    print("\nâœ¨ è‡ªå®šä¹‰LLMé…ç½®å®Œæˆï¼")
    print("\nğŸ’¡ æç¤º:")
    print("- å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥APIåœ°å€å’Œå¯†é’¥æ˜¯å¦æ­£ç¡®")
    print("- ç¡®ä¿æ‚¨çš„LLMæœåŠ¡æ”¯æŒOpenAIå…¼å®¹çš„APIæ ¼å¼")
    print("- å¯ä»¥å‚è€ƒæœ¬åœ°LLMä½¿ç”¨æŒ‡å—.mdäº†è§£æ›´å¤šä¿¡æ¯")

if __name__ == "__main__":
    main()