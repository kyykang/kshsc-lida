#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIDA æœ¬åœ°LLMå¯åŠ¨è„šæœ¬
æ— éœ€OpenAI APIå¯†é’¥ï¼Œä½¿ç”¨æœ¬åœ°å¤§è¯­è¨€æ¨¡å‹

ä½¿ç”¨æ–¹æ³•:
1. python start_with_local_llm.py --model huggingface
2. python start_with_local_llm.py --model ollama
3. python start_with_local_llm.py --model vllm

ä½œè€…: AIåŠ©æ‰‹
æ—¥æœŸ: 2024
"""

import os
import sys
import argparse
import uvicorn
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def setup_local_model(model_type):
    """
    æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®æœ¬åœ°LLM
    
    Args:
        model_type (str): æ¨¡å‹ç±»å‹ ('huggingface', 'ollama', 'vllm')
    
    Returns:
        Manager: é…ç½®å¥½çš„LIDAç®¡ç†å™¨
    """
    from lida import Manager, llm
    
    print(f"ğŸ¤– æ­£åœ¨é…ç½® {model_type} æœ¬åœ°æ¨¡å‹...")
    
    try:
        if model_type == "huggingface":
            # ä½¿ç”¨è½»é‡çº§çš„HuggingFaceæ¨¡å‹
            print("ä½¿ç”¨HuggingFaceæ¨¡å‹: microsoft/DialoGPT-medium")
            text_gen = llm(
                provider="hf",
                model="microsoft/DialoGPT-medium",
                device_map="auto"
            )
            
        elif model_type == "ollama":
            # ä½¿ç”¨OllamaæœåŠ¡å™¨
            print("è¿æ¥åˆ°OllamaæœåŠ¡å™¨ (localhost:11434)")
            model_details = [{
                'name': "llama2",
                'max_tokens': 2048,
                'model': {
                    'provider': 'openai',
                    'parameters': {'model': "llama2"}
                }
            }]
            
            text_gen = llm(
                provider="openai",
                api_base="http://localhost:11434/v1",
                api_key="ollama",
                models=model_details
            )
            
        elif model_type == "vllm":
            # ä½¿ç”¨vLLMæœåŠ¡å™¨
            print("è¿æ¥åˆ°vLLMæœåŠ¡å™¨ (localhost:8000)")
            model_details = [{
                'name': "microsoft/DialoGPT-medium",
                'max_tokens': 2596,
                'model': {
                    'provider': 'openai',
                    'parameters': {'model': "microsoft/DialoGPT-medium"}
                }
            }]
            
            text_gen = llm(
                provider="openai",
                api_base="http://localhost:8000/v1",
                api_key="EMPTY",
                models=model_details
            )
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        
        # åˆ›å»ºLIDAç®¡ç†å™¨
        lida_manager = Manager(text_gen=text_gen)
        print(f"âœ… {model_type} æ¨¡å‹é…ç½®æˆåŠŸï¼")
        
        return lida_manager
        
    except Exception as e:
        print(f"âŒ {model_type} æ¨¡å‹é…ç½®å¤±è´¥: {e}")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        
        if model_type == "huggingface":
            print("1. å®‰è£…ä¾èµ–: pip install transformers torch")
            print("2. ç¡®ä¿æœ‰è¶³å¤Ÿçš„GPU/CPUå†…å­˜")
            print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼ˆé¦–æ¬¡ä¸‹è½½æ¨¡å‹éœ€è¦ï¼‰")
            
        elif model_type == "ollama":
            print("1. å®‰è£…Ollama: curl -fsSL https://ollama.ai/install.sh | sh")
            print("2. å¯åŠ¨æœåŠ¡: ollama serve")
            print("3. ä¸‹è½½æ¨¡å‹: ollama pull llama2")
            
        elif model_type == "vllm":
            print("1. å®‰è£…vLLM: pip install vllm")
            print("2. å¯åŠ¨æœåŠ¡å™¨: python -m vllm.entrypoints.openai.api_server --model microsoft/DialoGPT-medium")
            
        return None

def create_local_app(lida_manager):
    """
    åˆ›å»ºä½¿ç”¨æœ¬åœ°æ¨¡å‹çš„FastAPIåº”ç”¨
    
    Args:
        lida_manager (Manager): é…ç½®å¥½çš„LIDAç®¡ç†å™¨
    
    Returns:
        FastAPI: é…ç½®å¥½çš„åº”ç”¨å®ä¾‹
    """
    import json
    import logging
    import requests
    from fastapi import FastAPI, UploadFile
    from fastapi.staticfiles import StaticFiles
    from fastapi.middleware.cors import CORSMiddleware
    import traceback
    
    from lida.datamodel import (
        GoalWebRequest, SummaryUrlRequest, TextGenerationConfig, 
        VisualizeWebRequest, InfographicsRequest
    )
    
    # åˆ›å»ºåº”ç”¨
    app = FastAPI(title="LIDA Local LLM")
    logger = logging.getLogger("lida")
    
    # æ·»åŠ CORSä¸­é—´ä»¶
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["http://localhost:8080", "http://127.0.0.1:8080"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )
    
    # åˆ›å»ºAPIè·¯ç”±
    api = FastAPI(root_path="/api")
    app.mount("/api", api)
    
    # è®¾ç½®é™æ€æ–‡ä»¶ç›®å½•
    root_file_path = os.path.dirname(os.path.abspath(__file__))
    static_folder_root = os.path.join(root_file_path, "lida/web/ui")
    files_static_root = os.path.join(root_file_path, "lida/web/files/")
    data_folder = os.path.join(root_file_path, "lida/web/files/data")
    
    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    os.makedirs(data_folder, exist_ok=True)
    os.makedirs(files_static_root, exist_ok=True)
    
    # æŒ‚è½½é™æ€æ–‡ä»¶
    if os.path.exists(static_folder_root):
        app.mount("/", StaticFiles(directory=static_folder_root, html=True), name="ui")
    api.mount("/files", StaticFiles(directory=files_static_root, html=True), name="files")
    
    @api.post("/summarize")
    async def upload_file(file: UploadFile):
        """ä¸Šä¼ æ–‡ä»¶å¹¶è¿”å›æ•°æ®æ‘˜è¦"""
        allowed_types = [
            "text/csv", 
            "application/vnd.ms-excel", 
            "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", 
            "application/json"
        ]
        
        if file.content_type not in allowed_types:
            return {
                "status": False,
                "message": f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ ({file.content_type})ã€‚æ”¯æŒçš„ç±»å‹: csv, excel, json"
            }
        
        try:
            # ä¿å­˜æ–‡ä»¶
            file_location = os.path.join(data_folder, file.filename)
            with open(file_location, "wb+") as file_object:
                file_object.write(file.file.read())
            
            # ç”Ÿæˆæ‘˜è¦ï¼ˆä½¿ç”¨åŸºç¡€æ‘˜è¦ï¼Œä¸ä¾èµ–LLMï¼‰
            print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {file.filename}")
            summary = lida_manager.summarize(
                data=file_location,
                file_name=file.filename,
                summary_method="default"  # ä½¿ç”¨åŸºç¡€æ‘˜è¦
            )
            
            return {
                "status": True, 
                "summary": summary, 
                "data_filename": file.filename
            }
            
        except Exception as exception_error:
            logger.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(exception_error)}")
            return {
                "status": False, 
                "message": f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(exception_error)}"
            }
    
    @api.post("/goal")
    async def generate_goal(req: GoalWebRequest):
        """æ ¹æ®æ•°æ®æ‘˜è¦ç”Ÿæˆå¯è§†åŒ–ç›®æ ‡"""
        try:
            textgen_config = req.textgen_config if req.textgen_config else TextGenerationConfig()
            goals = lida_manager.goals(req.summary, n=req.n, textgen_config=textgen_config)
            return {
                "status": True, 
                "data": goals,
                "message": f"æˆåŠŸç”Ÿæˆ {len(goals)} ä¸ªç›®æ ‡"
            }
        except Exception as exception_error:
            logger.error(f"ç”Ÿæˆç›®æ ‡æ—¶å‡ºé”™: {str(exception_error)}")
            return {
                "status": False,
                "message": f"ç”Ÿæˆç›®æ ‡æ—¶å‡ºé”™: {exception_error}"
            }
    
    @api.post("/visualize")
    async def visualize_data(req: VisualizeWebRequest):
        """æ ¹æ®ç›®æ ‡ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        try:
            charts = lida_manager.visualize(
                summary=req.summary,
                goal=req.goal,
                textgen_config=req.textgen_config if req.textgen_config else TextGenerationConfig(),
                library=req.library, 
                return_error=True
            )
            
            if len(charts) == 0:
                return {"status": False, "message": "æœªç”Ÿæˆä»»ä½•å›¾è¡¨"}
                
            return {
                "status": True, 
                "charts": charts,
                "message": "æˆåŠŸç”Ÿæˆå›¾è¡¨"
            }
            
        except Exception as exception_error:
            logger.error(f"ç”Ÿæˆå¯è§†åŒ–æ—¶å‡ºé”™: {str(exception_error)}")
            return {
                "status": False,
                "message": f"ç”Ÿæˆå¯è§†åŒ–æ—¶å‡ºé”™: {str(exception_error)}"
            }
    
    @api.get("/health")
    async def health_check():
        """å¥åº·æ£€æŸ¥æ¥å£"""
        return {
            "status": "healthy",
            "model_type": "local_llm",
            "message": "LIDAæœ¬åœ°æ¨¡å‹æœåŠ¡æ­£å¸¸è¿è¡Œ"
        }
    
    return app

def main():
    """
    ä¸»å‡½æ•°ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶å¯åŠ¨æœåŠ¡
    """
    parser = argparse.ArgumentParser(description="LIDA æœ¬åœ°LLMå¯åŠ¨å·¥å…·")
    parser.add_argument(
        "--model", 
        choices=["huggingface", "ollama", "vllm"],
        default="huggingface",
        help="é€‰æ‹©æœ¬åœ°æ¨¡å‹ç±»å‹ (é»˜è®¤: huggingface)"
    )
    parser.add_argument(
        "--host", 
        default="127.0.0.1",
        help="æœåŠ¡å™¨åœ°å€ (é»˜è®¤: 127.0.0.1)"
    )
    parser.add_argument(
        "--port", 
        type=int,
        default=8080,
        help="æœåŠ¡å™¨ç«¯å£ (é»˜è®¤: 8080)"
    )
    parser.add_argument(
        "--reload", 
        action="store_true",
        help="å¯ç”¨è‡ªåŠ¨é‡è½½"
    )
    
    args = parser.parse_args()
    
    print("ğŸš€ LIDA æœ¬åœ°LLMå¯åŠ¨å·¥å…·")
    print("=" * 50)
    print(f"æ¨¡å‹ç±»å‹: {args.model}")
    print(f"æœåŠ¡åœ°å€: http://{args.host}:{args.port}")
    print("=" * 50)
    
    # é…ç½®æœ¬åœ°æ¨¡å‹
    lida_manager = setup_local_model(args.model)
    if not lida_manager:
        print("âŒ æœ¬åœ°æ¨¡å‹é…ç½®å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
        sys.exit(1)
    
    # åˆ›å»ºåº”ç”¨
    app = create_local_app(lida_manager)
    
    print(f"\nğŸŒ å¯åŠ¨WebæœåŠ¡å™¨...")
    print(f"è®¿é—®åœ°å€: http://{args.host}:{args.port}")
    print("æŒ‰ Ctrl+C åœæ­¢æœåŠ¡")
    
    try:
        # å¯åŠ¨æœåŠ¡å™¨
        uvicorn.run(
            app,
            host=args.host,
            port=args.port,
            reload=args.reload
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ å¯åŠ¨æœåŠ¡æ—¶å‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()