#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è‡ªå®šä¹‰LLMé…ç½®æ˜¯å¦æ­£ç¡®
è¿™ä¸ªè„šæœ¬ä¼šéªŒè¯ä½ çš„LLMæœåŠ¡æ˜¯å¦èƒ½æ­£å¸¸å·¥ä½œ
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def test_direct_api():
    """
    ç›´æ¥æµ‹è¯•APIè¿æ¥
    ä¸ä¾èµ–LIDAï¼Œç›´æ¥è°ƒç”¨ä½ çš„LLMæœåŠ¡
    """
    import requests
    import json
    
    print("ğŸ” ç›´æ¥æµ‹è¯•APIè¿æ¥...")
    
    api_url = "http://10.254.28.17:30000/v1/chat/completions"
    
    # æ„é€ è¯·æ±‚æ•°æ®
    data = {
        "model": "default",
        "messages": [
            {"role": "user", "content": "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±"}
        ],
        "max_tokens": 100,
        "temperature": 0.7
    }
    
    try:
        response = requests.post(
            api_url,
            json=data,
            headers={"Content-Type": "application/json"},
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            if 'choices' in result and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content']
                print(f"âœ… APIæµ‹è¯•æˆåŠŸï¼")
                print(f"ğŸ“ å›å¤å†…å®¹: {content[:100]}...")
                return True
            else:
                print(f"âŒ APIè¿”å›æ ¼å¼å¼‚å¸¸: {result}")
                return False
        else:
            print(f"âŒ APIè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ APIè¿æ¥å¤±è´¥: {e}")
        return False

def test_llmx_openai_provider():
    """
    æµ‹è¯•llmxçš„OpenAI provider
    å°è¯•é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®API base
    """
    print("\nğŸ§ª æµ‹è¯•llmx OpenAI provider...")
    
    try:
        from llmx import llm
        
        # æ–¹æ³•1: é€šè¿‡ç¯å¢ƒå˜é‡è®¾ç½®
        original_base = os.environ.get('OPENAI_API_BASE')
        original_key = os.environ.get('OPENAI_API_KEY')
        
        try:
            # è®¾ç½®ç¯å¢ƒå˜é‡
            os.environ['OPENAI_API_BASE'] = 'http://10.254.28.17:30000/v1'
            os.environ['OPENAI_API_KEY'] = 'EMPTY'
            
            print("å°è¯•é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®...")
            text_gen = llm(provider="openai")
            print("âœ… é€šè¿‡ç¯å¢ƒå˜é‡åˆ›å»ºæˆåŠŸï¼")
            
            # å°è¯•ç”Ÿæˆæ–‡æœ¬
            try:
                response = text_gen.generate("ä½ å¥½")
                print(f"âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸ: {response[:50]}...")
                return text_gen, "ç¯å¢ƒå˜é‡é…ç½®"
            except Exception as gen_e:
                print(f"âš ï¸  æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {gen_e}")
                
        finally:
            # æ¢å¤åŸå§‹ç¯å¢ƒå˜é‡
            if original_base is not None:
                os.environ['OPENAI_API_BASE'] = original_base
            elif 'OPENAI_API_BASE' in os.environ:
                del os.environ['OPENAI_API_BASE']
                
            if original_key is not None:
                os.environ['OPENAI_API_KEY'] = original_key
            elif 'OPENAI_API_KEY' in os.environ:
                del os.environ['OPENAI_API_KEY']
        
        # æ–¹æ³•2: å°è¯•ç›´æ¥ä¼ é€’å‚æ•°
        test_params = [
            {"name": "openai_api_base", "openai_api_base": "http://10.254.28.17:30000/v1", "openai_api_key": "EMPTY"},
            {"name": "api_base", "api_base": "http://10.254.28.17:30000/v1", "api_key": "EMPTY"},
            {"name": "base_url", "base_url": "http://10.254.28.17:30000/v1", "api_key": "EMPTY"},
        ]
        
        for params in test_params:
            try:
                name = params.pop("name")
                print(f"\nå°è¯• {name} å‚æ•°...")
                text_gen = llm(provider="openai", **params)
                print(f"âœ… {name} åˆ›å»ºæˆåŠŸï¼")
                
                # å°è¯•ç”Ÿæˆæ–‡æœ¬
                try:
                    response = text_gen.generate("ä½ å¥½")
                    print(f"âœ… æ–‡æœ¬ç”ŸæˆæˆåŠŸ: {response[:50]}...")
                    return text_gen, name
                except Exception as gen_e:
                    print(f"âš ï¸  æ–‡æœ¬ç”Ÿæˆå¤±è´¥: {gen_e}")
                    
            except Exception as e:
                print(f"âŒ {name} å¤±è´¥: {e}")
        
        return None, None
        
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥llmx: {e}")
        return None, None

def test_alternative_approach():
    """
    æµ‹è¯•æ›¿ä»£æ–¹æ¡ˆï¼šç›´æ¥ä½¿ç”¨OpenAIå®¢æˆ·ç«¯
    """
    print("\nğŸ”„ æµ‹è¯•æ›¿ä»£æ–¹æ¡ˆ...")
    
    try:
        import openai
        
        # åˆ›å»ºè‡ªå®šä¹‰OpenAIå®¢æˆ·ç«¯
        client = openai.OpenAI(
            base_url="http://10.254.28.17:30000/v1",
            api_key="EMPTY"
        )
        
        print("âœ… OpenAIå®¢æˆ·ç«¯åˆ›å»ºæˆåŠŸï¼")
        
        # æµ‹è¯•èŠå¤©å®Œæˆ
        try:
            response = client.chat.completions.create(
                model="default",
                messages=[
                    {"role": "user", "content": "ä½ å¥½"}
                ],
                max_tokens=50
            )
            
            content = response.choices[0].message.content
            print(f"âœ… OpenAIå®¢æˆ·ç«¯æµ‹è¯•æˆåŠŸ: {content[:50]}...")
            return client
            
        except Exception as e:
            print(f"âŒ OpenAIå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
            return None
            
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥openaiåº“")
        return None
    except Exception as e:
        print(f"âŒ OpenAIå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {e}")
        return None

def create_working_config(method, client=None):
    """
    åˆ›å»ºå¯å·¥ä½œçš„é…ç½®æ–‡ä»¶
    """
    print(f"\nğŸ“ åˆ›å»ºåŸºäº{method}çš„é…ç½®æ–‡ä»¶...")
    
    if method == "ç¯å¢ƒå˜é‡é…ç½®":
        config_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIDA è‡ªå®šä¹‰LLMé…ç½®æ–‡ä»¶ - ç¯å¢ƒå˜é‡æ–¹å¼
é…ç½®ç±»å‹: openai_compatible
ç”Ÿæˆæ—¶é—´: è‡ªåŠ¨ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
1. from custom_llm_config_working import get_lida_manager
2. lida = get_lida_manager()
3. å¼€å§‹ä½¿ç”¨LIDAè¿›è¡Œæ•°æ®å¯è§†åŒ–
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def get_lida_manager():
    """
    è·å–é…ç½®å¥½çš„LIDAç®¡ç†å™¨
    
    è¿”å›:
        Manager: é…ç½®å¥½çš„LIDAç®¡ç†å™¨å®ä¾‹
    """
    from lida import Manager, llm
    
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–è‡ªå®šä¹‰LLMæœåŠ¡...")
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['OPENAI_API_BASE'] = 'http://10.254.28.17:30000/v1'
    os.environ['OPENAI_API_KEY'] = 'EMPTY'
    
    # åˆ›å»ºæ–‡æœ¬ç”Ÿæˆå™¨
    text_gen = llm(provider="openai")
    
    # åˆ›å»ºLIDAç®¡ç†å™¨
    lida_manager = Manager(text_gen=text_gen)
    
    print("âœ… è‡ªå®šä¹‰LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼")
    print(f"APIåœ°å€: http://10.254.28.17:30000/v1")
    print(f"æ¨¡å‹åç§°: default")
    
    return lida_manager

def test_llm_service():
    """
    æµ‹è¯•LLMæœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    try:
        lida = get_lida_manager()
        print("\\nğŸ§ª æ­£åœ¨æµ‹è¯•LLMæœåŠ¡...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€å•çš„æµ‹è¯•é€»è¾‘
        print("âœ… LLMæœåŠ¡æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ LLMæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("LIDA è‡ªå®šä¹‰LLMé…ç½®")
    print("=" * 30)
    
    # æµ‹è¯•æœåŠ¡
    if test_llm_service():
        print("\\nğŸ‰ é…ç½®æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨LIDAäº†")
        print("\\nğŸ“ ä½¿ç”¨ç¤ºä¾‹:")
        print("from custom_llm_config_working import get_lida_manager")
        print("lida = get_lida_manager()")
        print("summary = lida.summarize('your_data.csv')")
    else:
        print("\\nâš ï¸  é…ç½®å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥è®¾ç½®")
'''
    elif method == "OpenAIå®¢æˆ·ç«¯":
        config_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LIDA è‡ªå®šä¹‰LLMé…ç½®æ–‡ä»¶ - OpenAIå®¢æˆ·ç«¯æ–¹å¼
é…ç½®ç±»å‹: openai_compatible
ç”Ÿæˆæ—¶é—´: è‡ªåŠ¨ç”Ÿæˆ

ä½¿ç”¨æ–¹æ³•:
1. from custom_llm_config_working import get_lida_manager
2. lida = get_lida_manager()
3. å¼€å§‹ä½¿ç”¨LIDAè¿›è¡Œæ•°æ®å¯è§†åŒ–
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

def get_lida_manager():
    """
    è·å–é…ç½®å¥½çš„LIDAç®¡ç†å™¨
    ä½¿ç”¨ç›´æ¥çš„OpenAIå®¢æˆ·ç«¯æ–¹å¼
    
    è¿”å›:
        Manager: é…ç½®å¥½çš„LIDAç®¡ç†å™¨å®ä¾‹
    """
    from lida import Manager
    import openai
    
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–è‡ªå®šä¹‰LLMæœåŠ¡...")
    
    # åˆ›å»ºè‡ªå®šä¹‰OpenAIå®¢æˆ·ç«¯
    client = openai.OpenAI(
        base_url="http://10.254.28.17:30000/v1",
        api_key="EMPTY"
    )
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æ–‡æœ¬ç”Ÿæˆå™¨åŒ…è£…å™¨
    class CustomTextGenerator:
        def __init__(self, client):
            self.client = client
            
        def generate(self, prompt, **kwargs):
            response = self.client.chat.completions.create(
                model="default",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=kwargs.get('max_tokens', 2048),
                temperature=kwargs.get('temperature', 0.7)
            )
            return response.choices[0].message.content
    
    text_gen = CustomTextGenerator(client)
    
    # åˆ›å»ºLIDAç®¡ç†å™¨
    lida_manager = Manager(text_gen=text_gen)
    
    print("âœ… è‡ªå®šä¹‰LLMæœåŠ¡åˆå§‹åŒ–æˆåŠŸï¼")
    print(f"APIåœ°å€: http://10.254.28.17:30000/v1")
    print(f"æ¨¡å‹åç§°: default")
    
    return lida_manager

def test_llm_service():
    """
    æµ‹è¯•LLMæœåŠ¡æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    try:
        lida = get_lida_manager()
        print("\\nğŸ§ª æ­£åœ¨æµ‹è¯•LLMæœåŠ¡...")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€å•çš„æµ‹è¯•é€»è¾‘
        print("âœ… LLMæœåŠ¡æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"âŒ LLMæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    print("LIDA è‡ªå®šä¹‰LLMé…ç½®")
    print("=" * 30)
    
    # æµ‹è¯•æœåŠ¡
    if test_llm_service():
        print("\\nğŸ‰ é…ç½®æˆåŠŸï¼ç°åœ¨å¯ä»¥ä½¿ç”¨LIDAäº†")
        print("\\nğŸ“ ä½¿ç”¨ç¤ºä¾‹:")
        print("from custom_llm_config_working import get_lida_manager")
        print("lida = get_lida_manager()")
        print("summary = lida.summarize('your_data.csv')")
    else:
        print("\\nâš ï¸  é…ç½®å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥è®¾ç½®")
'''
    else:
        return False
    
    try:
        with open('custom_llm_config_working.py', 'w', encoding='utf-8') as f:
            f.write(config_content)
        print(f"âœ… å¯å·¥ä½œçš„é…ç½®æ–‡ä»¶å·²åˆ›å»º: custom_llm_config_working.py")
        return True
    except Exception as e:
        print(f"âŒ åˆ›å»ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False

def main():
    """
    ä¸»æµ‹è¯•å‡½æ•°
    æŒ‰æ­¥éª¤æµ‹è¯•å„ä¸ªç»„ä»¶
    """
    print("ğŸš€ å¼€å§‹æµ‹è¯•è‡ªå®šä¹‰LLMé…ç½®")
    print("=" * 50)
    
    # æ­¥éª¤1: ç›´æ¥æµ‹è¯•API
    api_ok = test_direct_api()
    
    if not api_ok:
        print("\nâŒ APIæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥:")
        print("1. LLMæœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
        print("2. æœåŠ¡åœ°å€æ˜¯å¦æ­£ç¡®: http://10.254.28.17:30000")
        print("3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸")
        return
    
    # æ­¥éª¤2: æµ‹è¯•llmxå…¼å®¹æ€§
    text_gen, config_name = test_llmx_openai_provider()
    
    if text_gen is not None:
        print(f"\nâœ… æ‰¾åˆ°å¯ç”¨çš„llmxé…ç½®: {config_name}")
        
        # æµ‹è¯•LIDAé›†æˆ
        try:
            from lida import Manager
            lida_manager = Manager(text_gen=text_gen)
            print("âœ… LIDAé›†æˆæµ‹è¯•é€šè¿‡ï¼")
            
            # åˆ›å»ºå¯å·¥ä½œçš„é…ç½®æ–‡ä»¶
            create_working_config(config_name)
            
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
            print("\nä¸‹ä¸€æ­¥å¯ä»¥:")
            print("1. ä½¿ç”¨: python custom_llm_config_working.py æµ‹è¯•é…ç½®")
            print("2. åœ¨ä»£ç ä¸­ä½¿ç”¨:")
            print("   from custom_llm_config_working import get_lida_manager")
            print("   lida = get_lida_manager()")
            return
            
        except Exception as e:
            print(f"âŒ LIDAé›†æˆå¤±è´¥: {e}")
    
    # æ­¥éª¤3: å°è¯•æ›¿ä»£æ–¹æ¡ˆ
    print("\nğŸ”„ llmxæ–¹å¼å¤±è´¥ï¼Œå°è¯•æ›¿ä»£æ–¹æ¡ˆ...")
    client = test_alternative_approach()
    
    if client is not None:
        print("\nâœ… æ‰¾åˆ°å¯ç”¨çš„æ›¿ä»£æ–¹æ¡ˆ: OpenAIå®¢æˆ·ç«¯")
        
        # åˆ›å»ºåŸºäºOpenAIå®¢æˆ·ç«¯çš„é…ç½®
        if create_working_config("OpenAIå®¢æˆ·ç«¯", client):
            print("\nğŸ‰ æ›¿ä»£æ–¹æ¡ˆé…ç½®æˆåŠŸï¼")
            print("\nä¸‹ä¸€æ­¥å¯ä»¥:")
            print("1. ä½¿ç”¨: python custom_llm_config_working.py æµ‹è¯•é…ç½®")
            print("2. åœ¨ä»£ç ä¸­ä½¿ç”¨:")
            print("   from custom_llm_config_working import get_lida_manager")
            print("   lida = get_lida_manager()")
        else:
            print("âŒ åˆ›å»ºæ›¿ä»£é…ç½®å¤±è´¥")
    else:
        print("\nâŒ æ‰€æœ‰æ–¹æ¡ˆéƒ½å¤±è´¥äº†")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥LLMæœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        print("2. æ›´æ–°ç›¸å…³åº“: python3 -m pip install -U llmx openai lida")
        print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main()